{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 637 ms, total: 1.98 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, ensemble, tree, metrics, preprocessing\n",
    "# from sklearn import ensemble\n",
    "# from sklearn.decomposition import RandomizedPCA\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.feature_selection import SelectKBest, RFECV, SelectFromModel\n",
    "# from sklearn import tree\n",
    "# from sklearn import metrics\n",
    "# from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 5.22 s, total: 37.8 s\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp_train_2014_1 = pd.read_csv('CAX_Train_2014_Jan_to_Jun.csv')\n",
    "temp_train_2014_2 = pd.read_csv('CAX_Train_2014_Jul_to_Dec.csv')\n",
    "temp_train_2015 = pd.read_csv('CAX_Train_2015.csv')\n",
    "testing = pd.read_csv('CAX_TestSet.csv')\n",
    "# orig_weather = pd.read_csv('weather.csv')\n",
    "#dest_weather = orig_weather.copy(deep=True)\n",
    "# codes = pd.read_csv('airport-codes.csv')\n",
    "# airports = pd.read_csv('airports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 18.9 s, total: 48.8 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp_training = pd.concat([temp_train_2014_1, temp_train_2014_2, temp_train_2015], ignore_index=True)\n",
    "delayed = temp_training[temp_training['ARR_DEL15'] == 1]\n",
    "on_time = temp_training[temp_training['ARR_DEL15'] == 0]\n",
    "sample_rows = np.random.choice(on_time.index.values, (len(delayed) * 2))\n",
    "on_time = on_time.ix[sample_rows]\n",
    "training = pd.concat([on_time, delayed], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.base import TransformerMixin\n",
    "# class DataFrameImputer(TransformerMixin):\n",
    "#     def fit(self, X, y=None):\n",
    "#         self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "#             if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "#             index=X.columns)\n",
    "#         return self\n",
    "#     def transform(self, X, y=None):\n",
    "#         return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# training_imputed = DataFrameImputer().fit_transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.8 s, sys: 1.24 s, total: 48.1 s\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training.UNIQUE_CARRIER = le.fit_transform(training.UNIQUE_CARRIER)\n",
    "training.ORIGIN = le.fit_transform(training.ORIGIN)\n",
    "training.ORIGIN_CITY_NAME = le.fit_transform(training.ORIGIN_CITY_NAME)\n",
    "training.ORIGIN_STATE_ABR = le.fit_transform(training.ORIGIN_STATE_ABR)\n",
    "training.DEST = le.fit_transform(training.DEST)\n",
    "training.DEST_CITY_NAME = le.fit_transform(training.DEST_CITY_NAME)\n",
    "training.DEST_STATE_ABR = le.fit_transform(training.DEST_STATE_ABR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 µs, sys: 83 µs, total: 147 µs\n",
      "Wall time: 140 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = [c for c in training.columns if c not in ['FL_DATE', 'FL_NUM', 'TAIL_NUM', 'DEP_TIME_BLK', 'ARR_TIME_BLK', 'ARR_DEL15', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 5.49 s, total: 16.1 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(training[features], training['ARR_DEL15'], test_size=0.50)\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features_train, labels_train, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def modelfit(alg, features, labels, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(features.values, label=labels.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(features, labels, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(features)\n",
    "    dtrain_predprob = alg.predict_proba(features)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(labels.values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(labels, dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Choose all predictors except target & IDcols\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate =0.3,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=50, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(features_train.values, labels_train.values)\n",
    "print gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27).fit(features_train.values, labels_train.values)\n",
    "# forest = ensemble.RandomForestClassifier(min_samples_split=50, n_estimators=100, n_jobs=-1).fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pred = gbm.predict(features_test.values)\n",
    "# pred = forest.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels_test.values, pred)\n",
    "print metrics.roc_auc_score(fpr, tpr)\n",
    "# print metrics.accuracy_score(pred, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame(training['ORIGIN'].values).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes_iata = pd.DataFrame(codes[['iata_code', 'gps_code']]).drop_duplicates('iata_code')\n",
    "codes_iata = codes_iata.dropna()\n",
    "codes_iata = codes_iata[codes_iata.iata_code != '0']\n",
    "print len(codes_iata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_test = pd.merge(training, codes_iata, left_on='ORIGIN', right_on='iata_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(training), len(training_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_hour = [str((i/100) * 100) if (i % 100) < 50 else str((i/100) * 100 + 100) for i in training['CRS_DEP_TIME'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "training['DEP_HOUR'] = [str((i/100) * 100) if (i % 100) < 30 else str((i/100) * 100 + 100) for i in training['CRS_DEP_TIME'].values]\n",
    "training['ARR_HOUR'] = [str((i/100) * 100) if (i % 100) < 30 else str((i/100) * 100 + 100) for i in training['CRS_ARR_TIME'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "orig_weather.columns = ['ORIG_DATE', 'ORIG_TIME', 'ORIG_TIME_BLK', 'ORIG_CITY', 'ORIG_STATE', 'ORIG_ZIP', 'ORIG_AIRPORT_CODE', 'ORIG_TIME_CST', 'ORIG_DATE_UTC', 'ORIG_TEMPERATURE_F', 'ORIG_DEW_POINT_F', 'ORIG_HUMIDITY', 'ORIG_SEA_LEVEL_PRESSURE_IN', 'ORIG_VISIBILITY_MPH', 'ORIG_WIND_DIRECTION', 'ORIG_WIND_SPEED_MPH', 'ORIG_GUST_SPEED_MPH', 'ORIG_PRECIPITATION_IN', 'ORIG_EVENTS', 'ORIG_CONDITIONS', 'ORIG_WIND_DIR_DEGREES']\n",
    "#dep_weather.columns = ['DEST_DATE', 'DEST_TIME', 'DEST_TIME_BLK', 'DEST_CITY', 'DEST_STATE', 'DEST_ZIP', 'DEST_AIRPORT_CODE', 'DEST_TIME_CST', 'DEST_DATE_UTC', 'DEST_TEMPERATURE_F', 'DEST_DEW_POINT_F', 'DEST_HUMIDITY', 'DEST_SEA_LEVEL_PRESSURE_IN', 'DEST_VISIBILITY_MPH', 'DEST_WIND_DIRECTION', 'DEST_WIND_SPEED_MPH', 'DEST_GUST_SPEED_MPH', 'DEST_PRECIPITATION_IN', 'DEST_EVENTS', 'DEST_CONDITIONS', 'DEST_WIND_DIR_DEGREES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_weather = pd.merge(orig_weather, codes[['gps_code', 'iata_code']], left_on='ORIG_AIRPORT_CODE', right_on='gps_code')\n",
    "#arr_weather = pd.merge(orig_weather, codes[['gps_code', 'local_code']], left_on='ORIG_AIRPORT_CODE', right_on='gps_code')\n",
    "#dep_weather = pd.merge(dest_weather, codes[['gps_code', 'local_code']], left_on='DEST_AIRPORT_CODE', right_on='gps_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# training_ww = pd.merge(training, test_weather, left_on=['FL_DATE', 'ORIGIN','ARR_TIME_BLK'], right_on=['ARR_DATE', 'local_code', 'ARR_TIME_BLK'])\n",
    "# training_ww = pd.merge(training_ww, dep_weather, left_on=['FL_DATE', 'DEST','DEP_TIME_BLK'], right_on=['DEP_DATE', 'local_code', 'DEP_TIME_BLK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# origin_state = pd.DataFrame(training.ORIGIN_STATE_ABR.drop_duplicates())\n",
    "# dest_state = pd.DataFrame(training.DEST_STATE_ABR.drop_duplicates())\n",
    "# print len(origin_state), len(dest_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arr_codes = arr_weather.ARR_AIRPORT_CODE.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# training_nw = training[~(training.id.isin(training_ww.id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(training), (len(training_ww) + len(training_nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with_dest_match = pd.merge(all_train, destinations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "testing.UNIQUE_CARRIER = le.fit_transform(testing.UNIQUE_CARRIER)\n",
    "testing.ORIGIN = le.fit_transform(testing.ORIGIN)\n",
    "testing.ORIGIN_CITY_NAME = le.fit_transform(testing.ORIGIN_CITY_NAME)\n",
    "testing.ORIGIN_STATE_ABR = le.fit_transform(testing.ORIGIN_STATE_ABR)\n",
    "testing.DEST = le.fit_transform(testing.DEST)\n",
    "testing.DEST_CITY_NAME = le.fit_transform(testing.DEST_CITY_NAME)\n",
    "testing.DEST_STATE_ABR = le.fit_transform(testing.DEST_STATE_ABR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_pred = pd.DataFrame(forest.predict(testing[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = testing['id']\n",
    "submission['ARR_DEL15'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
